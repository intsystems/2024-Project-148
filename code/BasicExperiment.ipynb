{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5331b339-1ccf-42f8-8085-668d5b94d705",
   "metadata": {},
   "outputs": [],
   "source": [
    "import artm\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "sns.set(style=\"darkgrid\", palette=\"Set2\")\n",
    "\n",
    "from topicnet.dataset_manager import api\n",
    "\n",
    "# topicnet imports\n",
    "from topicnet.cooking_machine.cubes import (\n",
    "    CubeCreator,\n",
    "    GreedyStrategy,\n",
    "    PerplexityStrategy,\n",
    "    RegularizationControllerCube,\n",
    "    RegularizersModifierCube,\n",
    ")\n",
    "from topicnet.cooking_machine.dataset import Dataset\n",
    "from topicnet.cooking_machine.experiment import Experiment\n",
    "from topicnet.cooking_machine.models import BaseScore\n",
    "from topicnet.cooking_machine.models.topic_model import TopicModel\n",
    "from topicnet.cooking_machine.model_constructor import add_standard_scores\n",
    "from topicnet.cooking_machine.model_constructor import init_simple_default_model\n",
    "from topicnet.cooking_machine.pretty_output import make_notebook_pretty\n",
    "from topicnet.viewers.top_documents_viewer import TopDocumentsViewer\n",
    "from topicnet.viewers.top_tokens_viewer import TopTokensViewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "98facaad-1fd0-4f36-a8cd-a31a4772629f",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_PATH = './data/exp/'\n",
    "\n",
    "DATASET_PATH = './data/20_News_dataset/train_preprocessed.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1b8dec-5d58-4f99-8981-7e303c1a2dcc",
   "metadata": {},
   "source": [
    "### Обучаем тематическую модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4595c10b-4072-4634-8b6e-2ce57b580ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(EXPERIMENT_PATH):\n",
    "    os.mkdir(EXPERIMENT_PATH)\n",
    "else:\n",
    "    ! rm -rf $EXPERIMENT_PATH\n",
    "    os.mkdir(EXPERIMENT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2b10d056-911f-43c0-9d35-93a323ec3bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.7 s, sys: 485 ms, total: 18.2 s\n",
      "Wall time: 13.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from topicnet.cooking_machine.recipes import BaselineRecipe\n",
    "\n",
    "training_pipeline = BaselineRecipe()\n",
    "\n",
    "training_pipeline.format_recipe(\n",
    "    dataset_path=DATASET_PATH,\n",
    "    topic_number=20,\n",
    "    background_topic_number=1,\n",
    ")\n",
    "experiment, dataset = training_pipeline.build_experiment_environment(save_path=EXPERIMENT_PATH,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fabf4a90-b108-47cf-8fd3-636c1be66583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 56min 25s, sys: 9min 24s, total: 1h 5min 49s\n",
      "Wall time: 31min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "models = experiment.run(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8b951511-fd64-45bb-998d-636ab2063f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = list(models)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a5f4b1-e2d7-40f6-bf27-0a1d68d43219",
   "metadata": {},
   "source": [
    "### Реализум и вычисляем когерентность Ньюмана с PPMI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81cc65e9-7322-436c-a12d-d4d69c984f9f",
   "metadata": {},
   "source": [
    "Метрики реализованные ниже не до конца отвечабт идеологии BigARTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "e93f248d-29ec-47b6-9ca7-abb6c68009ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from topicnet.cooking_machine.models.base_score import BaseScore\n",
    "from math import log\n",
    "\n",
    "class NewmanCoherence(BaseScore):\n",
    "    def __init__(self, dataset, windowSize = 10):\n",
    "        super().__init__()\n",
    "        self.windowSize = windowSize\n",
    "        \n",
    "        def lemmatizedField2List(s):\n",
    "            return s[2:-2].split(\"', '\")\n",
    "\n",
    "        self._documents  = [\n",
    "            lemmatizedField2List(doc) for doc in dataset.get_dataset()['lemmatized']\n",
    "        ]\n",
    "        self.n = windowSize * sum([len(d) for d in self._documents])\n",
    "\n",
    "    def _get_topics(self, model):\n",
    "        return list(model.get_phi().columns)\n",
    "\n",
    "    def _coh(self, u, v):\n",
    "        def getWordPositions(u, text):\n",
    "            return [i for i, w in enumerate(text) if u == w]\n",
    "\n",
    "        nUV, nU, nV = 0, 0, 0\n",
    "        for d in self._documents:\n",
    "            uPositions = getWordPositions(u, d)\n",
    "            vPositions = getWordPositions(v, d)\n",
    "\n",
    "            for i in uPositions:\n",
    "                nU += min(len(d), i + self.windowSize) - max(0, i - self.windowSize)\n",
    "\n",
    "            for i in vPositions:\n",
    "                nV += min(len(d), i + self.windowSize) - max(0, i - self.windowSize)\n",
    "            \n",
    "            for i in uPositions:\n",
    "                for j in vPositions:\n",
    "                    nUV += abs(i - j) <= self.windowSize\n",
    "\n",
    "        return 0 if self.n * nUV <= (nU * nV) else log(self.n * nUV / (nU * nV)) #Calculating PPMI\n",
    "\n",
    "    def _calculate_topic_coherence(self, topic, phi):\n",
    "        def getTopWords(distribution, k=10):\n",
    "            order = np.argsort(distribution)[::-1]\n",
    "            return distribution[order][:k]\n",
    "        \n",
    "        distribution = phi[topic]['@lemmatized']\n",
    "        topWords = getTopWords(distribution)\n",
    "        # print(topWords)\n",
    "\n",
    "        cohSum = 0\n",
    "        for u, pu in topWords.items():\n",
    "            for v, pv in topWords.items():\n",
    "                cohSum += self._coh(u, v)\n",
    "        return cohSum\n",
    "                \n",
    "\n",
    "    def call(self, model):\n",
    "        topics = self._get_topics(model)\n",
    "        phi = model.get_phi()\n",
    "        for t in topics:\n",
    "            print(t, self._calculate_topic_coherence(t, phi))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "32c15ec9-0f6d-4537-86db-8539ec215780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 230 ms, sys: 27.1 ms, total: 257 ms\n",
      "Wall time: 148 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "score = NewmanCoherence(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "d8ec5efe-5f60-4b46-b423-2ed94a42f85a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic_0 60.044523191944485\n",
      "topic_1 94.73637995520384\n",
      "topic_2 122.65889943512931\n",
      "topic_3 29.067204408256398\n",
      "topic_4 127.21952188160549\n",
      "topic_5 213.71734243693126\n",
      "topic_6 196.7035738379648\n",
      "topic_7 94.72148751563833\n",
      "topic_8 64.32479947188925\n",
      "topic_9 26.843900707918813\n",
      "topic_10 104.70641318908643\n",
      "topic_11 72.28746655695996\n",
      "topic_12 93.1461288502546\n",
      "topic_13 25.10779868294018\n",
      "topic_14 72.14282077516681\n",
      "topic_15 53.36126222314763\n",
      "topic_16 154.88312767987208\n",
      "topic_17 150.53446814216437\n",
      "topic_18 90.34491375863998\n",
      "topic_19 59.14516968328842\n",
      "bcg_20 34.15284011652685\n",
      "CPU times: user 8min 18s, sys: 2min 6s, total: 10min 25s\n",
      "Wall time: 5min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "score.call(final_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e07fd27-5b82-4742-bb54-49163362f496",
   "metadata": {},
   "source": [
    "### Реализум и вычисляем интерпретируемость"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "67a23edd-22fe-40cd-87e3-9bca6d0bd47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from topicnet.cooking_machine.models.base_score import BaseScore\n",
    "from math import log\n",
    "\n",
    "class ChainsInterpretability(BaseScore):\n",
    "    def __init__(self, chains, windowSize = 10):\n",
    "        super().__init__()\n",
    "        self.chains = chains\n",
    "\n",
    "    def _get_topics(self, model):\n",
    "        return list(model.get_phi().columns)\n",
    "    \n",
    "    def _calculate_interpretability(self, topics, phi):\n",
    "        result = pd.Series(np.zeros(len(topics)), index=topics)\n",
    "        for chain in self.chains:\n",
    "            probs = phi.loc['@lemmatized'].loc[chain].to_numpy()\n",
    "            likelyhood = np.log(probs).sum(axis=0)\n",
    "            optimalTopic = topics[np.argmax(likelyhood)]\n",
    "            result[optimalTopic] += np.max(likelyhood)\n",
    "        return result\n",
    "\n",
    "    def call(self, model):\n",
    "        topics = self._get_topics(model)\n",
    "        phi = model.get_phi()\n",
    "        result = self._calculate_interpretability(topics, phi)\n",
    "        for t, m in result.items():\n",
    "            print(t, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "1e749096-ae12-41dc-ab99-fdeac020bcf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9 µs, sys: 17 µs, total: 26 µs\n",
      "Wall time: 39.8 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "score = ChainsInterpretability([\n",
    "    ['sport', 'car'],\n",
    "    ['front', 'bumper'],\n",
    "    ['floppy', 'disk'],\n",
    "    ['fix', 'code']\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "a6c5bfad-1f32-4ca7-8569-b11114503648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic_0 -11.720755577087402\n",
      "topic_1 0.0\n",
      "topic_2 0.0\n",
      "topic_3 0.0\n",
      "topic_4 0.0\n",
      "topic_5 0.0\n",
      "topic_6 -7.897364616394043\n",
      "topic_7 0.0\n",
      "topic_8 0.0\n",
      "topic_9 -14.651784896850586\n",
      "topic_10 0.0\n",
      "topic_11 -12.029800415039062\n",
      "topic_12 0.0\n",
      "topic_13 0.0\n",
      "topic_14 0.0\n",
      "topic_15 0.0\n",
      "topic_16 0.0\n",
      "topic_17 0.0\n",
      "topic_18 0.0\n",
      "topic_19 0.0\n",
      "bcg_20 0.0\n",
      "CPU times: user 11.8 s, sys: 2.64 s, total: 14.4 s\n",
      "Wall time: 8.32 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "score.call(final_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab2def1-8ddc-4b9c-8689-a9d45673625e",
   "metadata": {},
   "source": [
    "### Expected results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1999f031-5131-461a-8b88-f762a5712a4a",
   "metadata": {},
   "source": [
    "Здесь мы считаем наши метрики и строим корреляцию между ними и интерпретируемостью"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "08e0fa45-cdb4-4dea-add2-6ffc250ef63e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"../expected_results.png\" width=\"500\" height=\"500\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image \n",
    "Image(url=\"../expected_results.png\", width=500, height=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b35f26-c851-4a57-9d47-611e0dfb2c78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
